### 1. `getSNOTEL.ipynb` (Spatial Filtering & Core Variables)
This notebook identifies which SNOTEL sites are physically located within your target domain and fetches core daily metrics (like precipitation or snow depth).

* **How it works:** * Loads a geographic boundary (e.g., Upper Colorado River Basin shapefile/geopackage).
    * Queries the CUAHSI WaterOneFlow web services (via the `ulmo` library) to get a master list of all SNOTEL sites.
    * Clips the SNOTEL sites to the target boundary using `geopandas`.
    * Loops through the clipped sites to download historical daily data (e.g., `PRCPSA_D` for precipitation or `SNWD_D` for snow depth) from 1950 to the present.
* **Outputs:** * A GeoPackage (`.gpkg`) of the filtered sites.
    * A pickled pandas DataFrame (`.pkl`) containing the aggregated daily time-series data for all queried sites.

### 2. `get_snotel_soil_moisture.ipynb` (Deep Dive into Soil Metrics)
This notebook takes the list of sites generated by the first script and queries the USDA NRCS Report Generator API to pull detailed underground metrics.

* **How it works:**
    * Loads the pre-filtered sites (from the GeoPackage created in the first notebook).
    * Sets up a robust web request session (with automatic retries for timeouts) to hit the NRCS Report Generator.
    * Fetches Daily Soil Moisture (SMS) and Soil Temperature (STO) at five specific depths: -2", -4", -8", -20", and -40".
    * Cleans, renames, and reindexes the data to ensure a continuous daily timeline from 1999 to the present, dropping empty or invalid columns.
* **Outputs:** * Individual CSV files for each SNOTEL site containing its soil data.
    * Summary CSVs detailing which sites successfully returned data and which failed.
    * A master combined CSV (`all_sites_soil_combined.csv`) with a multi-index for bulk analysis.

## üõ†Ô∏è Requirements & Setup
To run these notebooks, you will need a Python environment with the following spatial and data science libraries installed:
* `pandas`
* `geopandas`
* `shapely`
* `ulmo`
* `requests`
* `matplotlib`
* `numpy`

**Note on File Paths:** Both notebooks currently use hardcoded local file paths (e.g., `/Users/wcurrier/Documents/...`). You will need to update these `gpkg_file_path` and `output_dir` variables to match your local machine's directory structure before running.
